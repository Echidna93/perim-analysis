summary(post.samples)
Nparms <- 3
cwdMat
cwdMat <- matrix(0,nrow=nrow(cwdMat2), ncol=(ncol(cwdMat2)+1))
for(i in 1:nrow(cwdMat2)){
for(j in 1:ncol(cwdMat2)){
cwdMat[i,j] <- as.numeric(cwdMat2[i,j])
}
}
cwdMat
cwdMat[,4] <- scale(cwdMat[,4])[,1]
cwdMat
cwdMat <- matrix(0,nrow=nrow(cwdMat2), ncol=(ncol(cwdMat2)+1))
for(i in 1:nrow(cwdMat2)){
for(j in 1:ncol(cwdMat2)){
cwdMat[i,j] <- as.numeric(cwdMat2[i,j])
}
}
scale(cwdMat[,4])
scale(cwdMat[,4])
scale(cwdMat[,5])
which(is.infinite(cwdMat[,4]))
cwdMat
cwdMat[1770,4] <- NA
which(is.infinite(cwdMat[,4]))
any(is.infinite(cwdMat))
scale(cwdMat[,4])
cwdMat[,4] <- scale(cwdMat[,4])[,1]
cwdMat[,5] <- scale(cwdMat[,5])[,1]
#cwdMat[,ncol(cwdMat)-1] <- scale(cwdMat[,ncol(cwdMat)])[,1]
cwdMat[,ncol(cwdMat)] <- scale(cwdMat[,1])[,1]
cwdMat
unique(cwdMat[,ncol(cwdMat)])
cwdMat
modelcode <- nimbleCode({
# CAR mod
# likelihood
for(j in 2: (n.years)){
for (i in 1 : N) {
# beta[4] male
#phi.t.minus.1 <- theta[j,1] * (beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),1])
log(lambda[((N*(j-2))+i)]) <-  beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),Ncol] + phi[i] + theta[1]*(j-1) + beta0[(N*(j-2))+i]
# time lag term for zero process
#phi.hat.t.minus.1 <- theta[j,2] * (beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),1])
logit(p[((N*(j-2))+i)]) <-  beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),Ncol] + phi.hat[i] +
theta.hat[1]*(j-1) + beta0.hat[(N*(j-2))+i]
y[(N*(j-1)+i), 1] ~ dZIP(lambda[((N*(j-2))+i)],p[((N*(j-2))+i)])
}
}
## priors
for(i in 1:Nparms){
# hyperpriors for reg coeff
prec.beta[i] ~ dgamma(0.01, 0.01)
prec.beta.hat[i]~ dgamma(0.01, 0.01)
beta[i] ~ dnorm(0.0, sd = prec.beta[i])
beta.hat[i]~ dnorm(0.0, sd = prec.beta.hat[i])
}
prec.c ~ dgamma(0.01, 0.01)
prec.c.hat ~dgamma(0.01,0.01)
phi[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c, zero_mean=0)
phi.hat[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c.hat, zero_mean=0)
prec.beta0 ~ dgamma(0.01,0.01)
prec.beta0.hat ~ dgamma(0.01,0.01)
# beta 0 captures unstructured heterogeneity in the count and zero processes
for(j in 2:n.years){
for(i in 1:N){
beta0[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0)
beta0.hat[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0.hat)
}
}
for(j in 2:n.years){
#prec.theta[j] ~ dgamma(0.01, 0.01)
#prec.theta.hat[j] ~ dgamma(0.01, 0.01)
theta[j] ~ dunif(0,1)
theta.hat[j] ~ dunif(0,1)
}
})
## Specify data and initial valu)es
constants <- list(N = length(unique(wiTwnshpShp$uid)),
n.years=19,
Ncol = ncol(cwdMat),
Nparms = Nparms,
L = length(W$adj),
adj=W$adj,
num=W$num,
weights = W$weights
)
#M=wCarCM$M,
#C=wCarCM$C)
data <- list(y = cwdMat)
inits <- list(lambda = rep(0,length(unique(wiTwnshpShp$uid))*19),
p = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0  = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0.hat = rep(0,length(unique(wiTwnshpShp$uid))*19),
phi = rep(0,length(unique(wiTwnshpShp$uid))),
phi.hat = rep(0,length(unique(wiTwnshpShp$uid))),
prec.c = 1,
prec.c.hat = 1,
prec.m0 = rep(1,2),
prec.theta = rep(0,19),
prec.theta.hat = rep(0,19),
theta = rep(0,19),
theta.hat = rep(0,19),
prec.beta.hat = rep(1,5),
prec.beta = rep(1,5),
beta = rep(0,5),
beta.hat = rep(0,5))
## Build/Compile model, including steps:
## (1) build model (2) compile model in C++
## (3) specify MCMC parameters to collect and create MCMC algorithm
cwdspatmodel <- nimbleModel(modelcode, constants = constants, data = data, inits = inits)
## Build/Compile model, including steps:
## (1) build model (2) compile model in C++
## (3) specify MCMC parameters to collect and create MCMC algorithm
cwdspatmodel <- nimbleModel(modelcode, constants = constants, data = data, inits = inits)
c.cwdspatmodel <- compileNimble(cwdspatmodel, resetFunctions = TRUE)
confMC <- configureMCMC(cwdspatmodel, monitors = c('beta','beta.hat', 'theta', 'theta.hat'),
enableWAIC = TRUE)
cwdspatmcmc <- buildMCMC(confMC)
c.cwdspatmcmc <- compileNimble(cwdspatmcmc, project = cwdspatmodel, resetFunctions = TRUE)## Run MCMC
mcmc.out <- runMCMC(c.cwdspatmcmc,
niter=20000,
nburnin=10000, # should use 10k for a burnin period
thin = 1,
nchains=3,
WAIC=TRUE)
## convert post samples as mcmc.list object and diagnose convergence using coda functions
post.samples <- mcmc.list(sapply(mcmc.out$samples,
as.mcmc,simplify=FALSE))
plot(post.samples, trace=TRUE, density=FALSE)
modelcode <- nimbleCode({
# CAR mod
# likelihood
for(j in 2: (n.years)){
for (i in 1 : N) {
# beta[4] male
#phi.t.minus.1 <- theta[j,1] * (beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),1])
log(lambda[((N*(j-2))+i)]) <-  beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),Ncol] + phi[i] + theta*(j-1) + beta0[(N*(j-2))+i]
# time lag term for zero process
#phi.hat.t.minus.1 <- theta[j,2] * (beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),1])
logit(p[((N*(j-2))+i)]) <-  beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),Ncol] + phi.hat[i] +
theta.hat*(j-1) + beta0.hat[(N*(j-2))+i]
y[(N*(j-1)+i), 1] ~ dZIP(lambda[((N*(j-2))+i)],p[((N*(j-2))+i)])
}
}
## priors
for(i in 1:Nparms){
# hyperpriors for reg coeff
prec.beta[i] ~ dgamma(1, 0.01)
prec.beta.hat[i]~ dgamma(1, 0.01)
beta[i] ~ dnorm(0.0, sd = prec.beta[i])
beta.hat[i]~ dnorm(0.0, sd = prec.beta.hat[i])
}
prec.c ~ dgamma(1, 0.01)
prec.c.hat ~dgamma(1,0.01)
phi[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c, zero_mean=0)
phi.hat[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c.hat, zero_mean=0)
prec.beta0 ~ dgamma(1,0.01)
prec.beta0.hat ~ dgamma(1,0.01)
# beta 0 captures unstructured heterogeneity in the count and zero processes
for(j in 2:n.years){
for(i in 1:N){
beta0[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0)
beta0.hat[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0.hat)
}
}
prec.theta ~ dgamma(1, 0.01)
prec.theta.hat ~ dgamma(1, 0.01)
theta ~ dnorm(0,prec.theta)
theta.hat ~ dnorm(0,prec.theta.hat)
})
#M=wCarCM$M,
#C=wCarCM$C)
data <- list(y = cwdMat)
inits <- list(lambda = rep(0,length(unique(wiTwnshpShp$uid))*19),
p = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0  = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0.hat = rep(0,length(unique(wiTwnshpShp$uid))*19),
phi = rep(0,length(unique(wiTwnshpShp$uid))),
phi.hat = rep(0,length(unique(wiTwnshpShp$uid))),
prec.c = 1,
prec.c.hat = 1,
prec.theta = 1,
prec.theta.hat = 1,
theta = 0,
theta.hat = 0,
prec.beta.hat = rep(1,2),
prec.beta = rep(1,2),
beta = rep(0,2),
beta.hat = rep(0,2))
## Build/Compile model, including steps:
## (1) build model (2) compile model in C++
## (3) specify MCMC parameters to collect and create MCMC algorithm
cwdspatmodel <- nimbleModel(modelcode, constants = constants, data = data, inits = inits)
dZIP <- nimbleFunction(
run = function(x = integer(), lambda = double(),
zeroProb = double(), log = logical(0, default = 0)) {
returnType(double())
## First handle non-zero data
z <- dbinom(0,1,zeroProb)
if (x != 0) {
# the probability that it is not generated by our zero process
# and the probability that it is generated by the count process
return(dpois(x,(1-z)*lambda))
}
# if it is a zero then it could be produced by the count process
# and also (therefore) not be structural OR
# it is non-structural (dbinom)
return(dbinom(0,1, zeroProb) + dpois(0,(1-z)*lambda))
})
rZIP <- nimbleFunction(
run = function(n = integer(), lambda = double(),
zeroProb = double()) {
returnType(integer())
# if the zero-probability is high rbinom returns 1 returns 1
# and thus rZIP returns 0; this is a structural zero
isStructural = rbinom(1,prob=zeroProb,size=1)
if(isStructural) return(0)
# if it wasn't a structural zero, then return rpois(lambda)
# could still return non-structural zeros
return(rpois(1,lambda))
})
# let's create our expected value
registerDistributions(list(
dZIP = list(
BUGSdist = "dZIP(lambda, zeroProb)",
discrete = TRUE,
range = c(0, Inf),
types = c('value = integer()', 'lambda = double()', 'zeroProb = double()')
)))
modelcode <- nimbleCode({
# CAR mod
# likelihood
for(j in 2: (n.years)){
for (i in 1 : N) {
# beta[4] male
#phi.t.minus.1 <- theta[j,1] * (beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),1])
log(lambda[((N*(j-2))+i)]) <-  beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),Ncol] + phi[i] + theta*(j-1) + beta0[(N*(j-2))+i]
# time lag term for zero process
#phi.hat.t.minus.1 <- theta[j,2] * (beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),1])
logit(p[((N*(j-2))+i)]) <-  beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),Ncol] + phi.hat[i] +
theta.hat*(j-1) + beta0.hat[(N*(j-2))+i]
y[(N*(j-1)+i), 1] ~ dZIP(lambda[((N*(j-2))+i)],p[((N*(j-2))+i)])
}
}
## priors
for(i in 1:2){
# hyperpriors for reg coeff
prec.beta[i] ~ dgamma(1, 0.01)
prec.beta.hat[i]~ dgamma(1, 0.01)
beta[i] ~ dnorm(0.0, sd = prec.beta[i])
beta.hat[i]~ dnorm(0.0, sd = prec.beta.hat[i])
}
prec.c ~ dgamma(1, 0.01)
prec.c.hat ~dgamma(1,0.01)
phi[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c, zero_mean=0)
phi.hat[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c.hat, zero_mean=0)
prec.beta0 ~ dgamma(1,0.01)
prec.beta0.hat ~ dgamma(1,0.01)
# beta 0 captures unstructured heterogeneity in the count and zero processes
for(j in 2:n.years){
for(i in 1:N){
beta0[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0)
beta0.hat[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0.hat)
}
}
prec.theta ~ dgamma(1, 0.01)
prec.theta.hat ~ dgamma(1, 0.01)
theta ~ dnorm(0,prec.theta)
theta.hat ~ dnorm(0,prec.theta.hat)
})
## Specify data and initial valu)es
constants <- list(N = length(unique(wiTwnshpShp$uid)),
n.years=19,
Ncol = ncol(cwdMat),
Nparms = Nparms,
L = length(W$adj),
adj=W$adj,
num=W$num,
weights = W$weights
)
#M=wCarCM$M,
#C=wCarCM$C)
data <- list(y = cwdMat)
inits <- list(lambda = rep(0,length(unique(wiTwnshpShp$uid))*19),
p = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0  = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0.hat = rep(0,length(unique(wiTwnshpShp$uid))*19),
phi = rep(0,length(unique(wiTwnshpShp$uid))),
phi.hat = rep(0,length(unique(wiTwnshpShp$uid))),
prec.c = 1,
prec.c.hat = 1,
prec.theta = 1,
prec.theta.hat = 1,
theta = 0,
theta.hat = 0,
prec.beta.hat = rep(1,2),
prec.beta = rep(1,2),
beta = rep(0,2),
beta.hat = rep(0,2))
## Build/Compile model, including steps:
## (1) build model (2) compile model in C++
## (3) specify MCMC parameters to collect and create MCMC algorithm
cwdspatmodel <- nimbleModel(modelcode, constants = constants, data = data, inits = inits)
c.cwdspatmodel <- compileNimble(cwdspatmodel, resetFunctions = TRUE)
c.cwdspatmodel <- compileNimble(cwdspatmodel, resetFunctions = TRUE)
confMC <- configureMCMC(cwdspatmodel, monitors = c('beta','beta.hat', 'theta', 'theta.hat'),
enableWAIC = TRUE)
cwdspatmcmc <- buildMCMC(confMC)
c.cwdspatmcmc <- compileNimble(cwdspatmcmc, project = cwdspatmodel, resetFunctions = TRUE)## Run MCMC
mcmc.out <- runMCMC(c.cwdspatmcmc,
niter=20000,
nburnin=10000, # should use 10k for a burnin period
thin = 1,
nchains=3,
WAIC=TRUE)
## convert post samples as mcmc.list object and diagnose convergence using coda functions
post.samples <- mcmc.list(sapply(mcmc.out$samples,
as.mcmc,simplify=FALSE))
plot(post.samples, trace=TRUE, density=FALSE)
## posterior summary
summary(post.samples)
modelcode <- nimbleCode({
# CAR mod
# likelihood
for(j in 2: (n.years)){
for (i in 1 : N) {
# beta[4] male
#phi.t.minus.1 <- theta[j,1] * (beta[1]*y[(N*(j-1)+i),2] + beta[2]*y[(N*(j-2)+i),1])
log(lambda[((N*(j-2))+i)]) <-  beta[1]*y[(N*(j-1)+i),2] + phi[i] + theta*(j-1) + beta0[(N*(j-2))+i]
# time lag term for zero process
#phi.hat.t.minus.1 <- theta[j,2] * (beta.hat[1]*y[(N*(j-1)+i),2] + beta.hat[2]*y[(N*(j-2)+i),1])
logit(p[((N*(j-2))+i)]) <-  beta.hat[1]*y[(N*(j-1)+i),2] + phi.hat[i] + theta.hat*(j-1) + beta0.hat[(N*(j-2))+i]
y[(N*(j-1)+i), 1] ~ dZIP(lambda[((N*(j-2))+i)],p[((N*(j-2))+i)])
}
}
## priors
for(i in 1:2){
# hyperpriors for reg coeff
prec.beta[i] ~ dgamma(1, 0.01)
prec.beta.hat[i]~ dgamma(1, 0.01)
beta[i] ~ dnorm(0.0, sd = prec.beta[i])
beta.hat[i]~ dnorm(0.0, sd = prec.beta.hat[i])
}
prec.c ~ dgamma(1, 0.01)
prec.c.hat ~dgamma(1,0.01)
phi[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c, zero_mean=0)
phi.hat[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N],
prec.c.hat, zero_mean=0)
prec.beta0 ~ dgamma(1,0.01)
prec.beta0.hat ~ dgamma(1,0.01)
# beta 0 captures unstructured heterogeneity in the count and zero processes
for(j in 2:n.years){
for(i in 1:N){
beta0[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0)
beta0.hat[(N*(j-2)) + i] ~ dnorm(0.0,prec.beta0.hat)
}
}
prec.theta ~ dgamma(1, 0.01)
prec.theta.hat ~ dgamma(1, 0.01)
theta ~ dnorm(0,prec.theta)
theta.hat ~ dnorm(0,prec.theta.hat)
})
## Specify data and initial valu)es
constants <- list(N = length(unique(wiTwnshpShp$uid)),
n.years=19,
Ncol = ncol(cwdMat),
Nparms = Nparms,
L = length(W$adj),
adj=W$adj,
num=W$num,
weights = W$weights
)
#M=wCarCM$M,
#C=wCarCM$C)
data <- list(y = cwdMat)
inits <- list(lambda = rep(0,length(unique(wiTwnshpShp$uid))*19),
p = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0  = rep(0,length(unique(wiTwnshpShp$uid))*19),
beta0.hat = rep(0,length(unique(wiTwnshpShp$uid))*19),
phi = rep(0,length(unique(wiTwnshpShp$uid))),
phi.hat = rep(0,length(unique(wiTwnshpShp$uid))),
prec.c = 1,
prec.c.hat = 1,
prec.theta = 1,
prec.theta.hat = 1,
theta = 0,
theta.hat = 0,
prec.beta.hat = rep(1,2),
prec.beta = rep(1,2),
beta = rep(0,2),
beta.hat = rep(0,2))
c.cwdspatmodel <- compileNimble(cwdspatmodel, resetFunctions = TRUE)
library(mosaic)
library(mosaic)
library(dbplyr)
lake_char <- read.csv("lake_characteristics.csv")
lake_char <- read.csv("lake_characteristics.csv")
lake_info <- read.csv("lake_information.csv")
tally(~lake_states, data = lake_info)
# The lake characteristics data set doesn't have the states, so I am joining characteristics and info in order to be able to sort both data sets by state, and we also then have the info and characteristics in one data set
lake_all <- lake_info
lake_all <- lake_all %>%
left_join(lake_char, by = "lagoslakeid")
MN_lake <- lake_all %>%
filter(lake_states == "MN")
MN_lake
names(MN_lake)
lake_link <- read.csv("lake_link.csv")
names(lake_link)
epa_stuff<-read.csv("wsa_bencnt_genus_ts_final_part1.csv")
any(epa_stuff$SITE_ID %in% MN_lake$lagoslakeid)
any(epa_stuff$SITE_ID %in% MN_lake$lake_nhdid)
head(MN_lake$lake_nhdid)
head(MN_lake$lake_nhdftype)
head(MN_lake$lake_reachcode)
names(MN_lake)
head(MN_lake$lake_nhdfcode)
head(MN_lake$lake_namegnis)
head(MN_lake$lake_nhdid %in% epa_stuff$SITE_ID)
any(MN_lake$lake_nhdid %in% epa_stuff$SITE_ID)
merc<-read.csv("NRSA1819_Fish Tissue (Plugs)-Mercury.csv")
merc
library(lme4)
glmer(RESULT~1,data=merc,family="beta")
glmer(RESULT~NAME_COM,data=merc,family="beta")
glmer(RESULT~NAME_COM,data=merc,family=("beta"))
glmer(RESULT~NAME_COM,data=merc)
lmer(RESULT~NAME_COM,data=merc)
lmer(RESULT~LENGTH_1 + (1|NAME_COM),data=merc)
MOD1<-lmer(RESULT~LENGTH_1 + (1|NAME_COM),data=merc)
plot(MOD1)
check_model(MOD1)
overdispersion(MOD1)
dispersion_glmer(MOD1)
install.packages("blmeco")
library(blmeco)
merc
View(merc)
dispersion_glmer(MOD1)
MOD1
unique(merc$NAME_COM)
merc %>% tally(NAME_COM)
merc %>% group_by(NAME_COM) %>% summarise(n=n())
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% order()
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% sort
merc %>% group_by(NAME_COM) %>% summarise(n=n())
head(merc %>% group_by(NAME_COM) %>% summarise(n=n()),50)
print(merc %>% group_by(NAME_COM) %>% summarise(n=n()),50)
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% sort(n)
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n)
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n, desc)
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n, by="desc")
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n, by="asc")
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n)
merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n, desc)
m<-merc %>% group_by(NAME_COM) %>% summarise(n=n())
m
(m,50)
print(m,50)
m<-merc %>% group_by(NAME_COM) %>% summarise(n=n()) %>% arrange(n)
m
tail(m)
knitr::opts_chunk$set(echo = TRUE)
lsmDat
read.table("./data/lsmDat")
setwd("C:/Users/jackx/Desktop/perim-analysis")
read.table("./data/lsmDat")
lsmDat
lsmDat <- read.table("./data/lsmDat")
lsmDat
# RUN this chunk to make all other chunks less annoying
knitr::opts_chunk$set(echo = FALSE)
library("rgdal")
library("raster")
library("sf")
library("leafsync")
library("dplyr")
library("ggplot2")
library("stars")
library(spatialEco)
library(spatstat.random)
library(data.table)
library(geoR)
library(RColorBrewer)
library(spdep)
library(spatialreg)
library(classInt)
library(rgeos)
library(landscapemetrics)
library(nimble)
library(coda)
library(prism)
library(terra)
library(maps)
library(raster)
library(pscl)
library(tidyverse)
library(CARBayesST)
library(INLAspacetime)
library(lme4)
library(INLA)
#write.table(cwdDat2,"./data/cwd-long") # save table
cwdDat3 <- read.table("./data/cwd-long")
cwd.mod <- inla(posP ~ 1 + f(year, model = "rw2"), data = cwdDat3, family = "poisson")
